{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "#we are using 70% of data for training and 30% for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is a image and y is its label\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n",
    "#first index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in data there are huge numbers present like 171,81,212 so we need to normalise\n",
    "#it like 0.171, 0.81 , 0.212, but data will not change we are making it in between 1 and 0\n",
    "#1 and 0 have less difference so.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=1 means changing for columns \n",
    "x_train= tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test= tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00393124, 0.02332955, 0.02620568,\n",
       "        0.02625207, 0.17420356, 0.17566281, 0.28629534, 0.05664824,\n",
       "        0.51877786, 0.71632322, 0.77892406, 0.89301644, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05780486, 0.06524513,\n",
       "        0.16128198, 0.22713296, 0.22277047, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.368094  , 0.3747499 ,\n",
       "        0.79066747, 0.67980478, 0.61494005, 0.45002403, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12250613, 0.45858525, 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32420121, 0.15214552, 0.17865984,\n",
       "        0.25626376, 0.1573102 , 0.12298801, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04500225, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.28826244,\n",
       "        0.26543758, 0.34149427, 0.31128482, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1541463 , 0.28272888,\n",
       "        0.18358693, 0.37314701, 0.33153488, 0.26569767, 0.01601458,\n",
       "        0.        , 0.05945042, 0.19891229, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0253731 ,\n",
       "        0.00171577, 0.22713296, 0.33153488, 0.11664776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20500962, 0.33153488, 0.24625638, 0.00291174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01622378, 0.24897876, 0.32790981, 0.10191096,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04586451, 0.31235677, 0.32757096,\n",
       "        0.23335172, 0.14931733, 0.00129164, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10498298, 0.34940902,\n",
       "        0.3689874 , 0.34978968, 0.15370495, 0.04089933, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06551419,\n",
       "        0.27127137, 0.34978968, 0.32678448, 0.245396  , 0.05882702,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02333517, 0.12857881, 0.32549285, 0.41390126, 0.40743158,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32161793, 0.41390126, 0.54251585,\n",
       "        0.20001074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06697006,\n",
       "        0.18959827, 0.25300993, 0.32678448, 0.41390126, 0.45100715,\n",
       "        0.00625034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05110617, 0.19182076, 0.33339444,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.40899334, 0.39653769,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04117838, 0.16813739, 0.28960162, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.25961929, 0.12760592, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04431706, 0.11961607,\n",
       "        0.36545809, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.28877275, 0.111988  , 0.00258328, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05298497, 0.42752138, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.25273681, 0.11646967,\n",
       "        0.01312603, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37491383,\n",
       "        0.56222061, 0.66525569, 0.63253163, 0.48748768, 0.45852825,\n",
       "        0.43408872, 0.359873  , 0.17428513, 0.01425695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92705966,\n",
       "        0.82698729, 0.74473314, 0.63253163, 0.4084877 , 0.24466922,\n",
       "        0.22648107, 0.02359823, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is ready to go in cnn model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential() #what kind of model? -> Sequential  (a feed forward layer)\n",
    "model.add(tf.keras.layers.Flatten()) #takes aur 28x28(size of image) and makes it 1x784\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))# a simple fully connected layer\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))#we are having 10 outputs thats why softmax(multiple output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2608 - accuracy: 0.9242\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1061 - accuracy: 0.9674\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0754 - accuracy: 0.9766\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0532 - accuracy: 0.9832\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0417 - accuracy: 0.9868\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0321 - accuracy: 0.9894\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0259 - accuracy: 0.9915\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0211 - accuracy: 0.9927\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0115 - accuracy: 0.9958\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0086 - accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20770cc2c08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', # to optimize output (more productive)\n",
    "             loss='sparse_categorical_crossentropy', #how will we calculate the error to minimize loss\n",
    "             metrics=['accuracy'])\n",
    "#now we are training\n",
    "model.fit(x_train,y_train,epochs=15) #for 10 times model gonna compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 802us/step - loss: 0.1448 - accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "#lets check the loss and accuracy\n",
    "val_loss,val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14477920532226562"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761999845504761"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc\n",
    "#we are 0.96 % accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\omen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\OMEN\\Desktop\\Number detectation\\digit_model.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#now save aur model speciying its path\n",
    "model.save(r'C:\\Users\\OMEN\\Desktop\\Number detectation\\digit_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(r'C:\\Users\\OMEN\\Desktop\\Number detectation\\digit_model.model')\n",
    "predictions=new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0202184e-16, 4.0627021e-14, 3.0720731e-15, ..., 1.0000000e+00,\n",
       "        2.3024673e-21, 1.3465221e-12],\n",
       "       [1.9362101e-22, 5.1267680e-08, 1.0000000e+00, ..., 4.3675623e-15,\n",
       "        2.9075680e-17, 3.6268157e-26],\n",
       "       [1.9485962e-17, 9.9999976e-01, 2.1389596e-13, ..., 1.9116567e-07,\n",
       "        2.1231090e-08, 2.8107608e-14],\n",
       "       ...,\n",
       "       [3.1646084e-18, 2.8792460e-13, 4.9823301e-19, ..., 1.2566469e-11,\n",
       "        2.9054541e-14, 9.8194604e-08],\n",
       "       [2.5935764e-14, 6.7298915e-15, 4.5530790e-16, ..., 1.4517752e-12,\n",
       "        7.6728129e-06, 5.7544899e-16],\n",
       "       [3.6598001e-16, 3.3963845e-19, 1.1924068e-19, ..., 5.1103052e-24,\n",
       "        7.4796323e-16, 1.8337167e-25]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display predictions\n",
    "plt.imshow(x_train[30],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
